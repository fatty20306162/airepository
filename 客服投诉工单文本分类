import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from torch.utils.data import DataLoader, TensorDataset
from transformers import BertTokenizer, BertForSequenceClassification, AdamW

# 读取Excel数据
df = pd.read_excel('sampled_data.xlsx', sheet_name='Sheet1', engine='openpyxl')
texts = df['业务内容'].tolist()
labels = df['服务请求类型'].tolist()

# 标签编码
label_encoder = LabelEncoder()
labels_encoded = label_encoder.fit_transform(labels)

# 划分训练集、验证集和测试集
train_texts, test_texts, train_labels_encoded, test_labels_encoded = train_test_split(texts, labels_encoded,
                                                                                      test_size=0.2, random_state=42)
train_texts, val_texts, train_labels_encoded, val_labels_encoded = train_test_split(train_texts, train_labels_encoded,
                                                                                    test_size=0.2, random_state=42)

# 加载Bert tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

# 对文本进行编码和填充
train_encodings = tokenizer(train_texts, truncation=True, padding=True)
val_encodings = tokenizer(val_texts, truncation=True, padding=True)
test_encodings = tokenizer(test_texts, truncation=True, padding=True)

# 创建数据集
train_dataset = TensorDataset(
    torch.tensor(train_encodings['input_ids']),
    torch.tensor(train_encodings['attention_mask']),
    torch.tensor(train_labels_encoded)
)
val_dataset = TensorDataset(
    torch.tensor(val_encodings['input_ids']),
    torch.tensor(val_encodings['attention_mask']),
    torch.tensor(val_labels_encoded)
)
test_dataset = TensorDataset(
    torch.tensor(test_encodings['input_ids']),
    torch.tensor(test_encodings['attention_mask']),
    torch.tensor(test_labels_encoded)
)

# 模型初始化
model = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=len(label_encoder.classes_))

# 设置训练参数
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)
model.train()

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# 定义优化器和学习率调度器
#optimizer = AdamW(model.parameters(), lr=1e-5)
optimizer = AdamW(model.parameters(), lr=1e-5, no_deprecation_warning=True)

num_epochs = 10

# 训练循环
best_accuracy = 0.0
for epoch in range(num_epochs):
    model.train()
    total_loss = 0.0
    for batch in train_loader:
        input_ids = batch[0].to(device)
        attention_mask = batch[1].to(device)
        labels = batch[2].to(device)

        optimizer.zero_grad()

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        total_loss += loss.item()

        loss.backward()
        optimizer.step()

    # 验证循环
    model.eval()
    correct_predictions = 0
    total_predictions = 0
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch[0].to(device)
            attention_mask = batch[1].to(device)
            labels = batch[2].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=1)

            correct_predictions += torch.sum(predictions == labels).item()
            total_predictions += labels.size(0)

    accuracy = correct_predictions / total_predictions
    print(f'Epoch {epoch + 1}: Loss={total_loss:.4f}, Validation Accuracy={accuracy:.4f}')

    # 保存最佳模型
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        torch.save(model.state_dict(), 'best_model.pt')

# 加载最佳模型进行计算
model.load_state_dict(torch.load('best_model.pt'))
model.eval()

# 在测试集上进行预测
test_loader = DataLoader(test_dataset, batch_size=16)
correct_predictions = 0
total_predictions = 0
with torch.no_grad():
    for batch in test_loader:
        input_ids = batch[0].to(device)
        attention_mask = batch[1].to(device)
        labels = batch[2].to(device)

        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=1)

        correct_predictions += torch.sum(predictions == labels).item()
        total_predictions += labels.size(0)

test_accuracy = correct_predictions / total_predictions
print(f'Test Accuracy: {test_accuracy:.4f}')
